# Toxicity
> Un módulo que permite detectar palabras con toxicidad o insultos (en Español).
> Completamente usable para bots de Discord u otros.

## Contribuyendo
Para añadir palabras al entrenamiento y ayudar a que Toxicity sea mejor aún, puedes hacer una Pull Request en
el repositorio de [GitHub](https://github.com/Seyronh/toxicity) modificando el archivo JSON dentro de la carpeta **entrenamiento**.

En el array de `input` encontrarás varias palabras, algunas tóxicas y otras completamente normales.
Puedes añadir tantas palabras como quieras, no importa que sean tóxicas o normales, pero recuerda que **por cada palabra que añadas**, en el array de `output` deberás añadir un 0 si ésta es normal o un 1 si esta es tóxica.

¡No podemos esperar a recibir tu contribución!